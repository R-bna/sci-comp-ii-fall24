import numpy as np
import matplotlib.pyplot as plt

# Load your data
data = np.loadtxt('data.txt')  # Adjust path and format as necessary
x, y = data[:, 0], data[:, 1]

# Metropolis algorithm parameters
n_samples = 10000
m_samples = np.zeros(n_samples)
b_samples = np.zeros(n_samples)

# Initial guesses
m_current, b_current = 0, 0
sigma_m, sigma_b = 0.1, 0.1

# Function to calculate likelihood
def likelihood(m, b):
    return np.exp(-0.5 * np.sum((y - (m * x + b))**2))

# Metropolis sampling
for i in range(n_samples):
    m_proposed = np.random.normal(m_current, sigma_m)
    b_proposed = np.random.normal(b_current, sigma_b)
    
    L_current = likelihood(m_current, b_current)
    L_proposed = likelihood(m_proposed, b_proposed)
    
    alpha = L_proposed / L_current
    
    if np.random.rand() < alpha:
        m_current, b_current = m_proposed, b_proposed
    
    m_samples[i] = m_current
    b_samples[i] = b_current

# Plotting results
plt.figure(figsize=(10, 6))
plt.scatter(x, y, label='Data')
for _ in range(10):  # Plot 10 sample lines
    plt.plot(x, m_samples[np.random.randint(len(m_samples))] * x + 
             b_samples[np.random.randint(len(b_samples))], 
             color='r', alpha=0.1)
plt.xlabel('x')
plt.ylabel('y')
plt.title('Linear Regression with Samples from Posterior')
plt.legend()
plt.show()

# Posterior distribution
plt.figure(figsize=(8, 6))
plt.hexbin(m_samples, b_samples, gridsize=30, cmap='Blues')
plt.colorbar()
plt.xlabel('Slope (m)')
plt.ylabel('Intercept (b)')
plt.title('2-D Posterior Distribution')
plt.show()
